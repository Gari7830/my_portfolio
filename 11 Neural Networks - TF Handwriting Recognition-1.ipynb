{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d0a52",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2d94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 22:58:24.625118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "from tensorflow import random\n",
    "random.set_seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e03ccf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f085a",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20cb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "\n",
    "LOGGING_PATH = 'tensorboard_mnist_digit_logs/'\n",
    "\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477084a",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f51c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.66 ms, sys: 5.9 ms, total: 13.6 ms\n",
      "Wall time: 14.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9acf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea66c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f147b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 262 ms, total: 1.84 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74351f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 281 ms, sys: 54.5 ms, total: 336 ms\n",
      "Wall time: 374 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a287c5",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125696be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de832c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557ed0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a89db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab989bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numbers correspond to digits cathegories\n",
    "y_train_all[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c1af1",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c2a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scaling values over 255 so every value in our datasets is between 0 and 1 \n",
    "x_train_all, x_test = x_train_all / 255.0 , x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef1229",
   "metadata": {},
   "source": [
    "### Convert target values to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "160f86d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting from a sparse array to a full array \n",
    "# one-hot encoding transformation\n",
    "values = y_train_all[:5]\n",
    "np.eye(10)[values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dfe94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming datasets to one-hot encoding\n",
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "400474e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset contains now ten columns that will refer to the number of classes in it\n",
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f81cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_all = np.eye(NR_CLASSES)[y_test_all]\n",
    "y_test_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b978f",
   "metadata": {},
   "source": [
    "### Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e711b",
   "metadata": {},
   "source": [
    "**Challenge:** Split the training dataset into a smaller training dataset and a validation dataset for the features and the labels. Create four arrays: x_val, y_val, x_train and, y_train from x_train_all and y_train_all. Use the validation size of 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee5a96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the first 10k values\n",
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "\n",
    "# Using the last 50k values\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b712cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cae570",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9e340ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape argument holds dimensions, this arg is provided with None since we'll be sampling different data batches\n",
    "# to test model\n",
    "\n",
    "# features\n",
    "X = tf.placeholder(tf.float32, shape=[None, TOTAL_INPUTS], name='X')\n",
    "\n",
    "# labels \n",
    "# shape arg contains 10, corresponding the total cathegories of the dataset\n",
    "Y = tf.placeholder(tf.float32, shape=[None, NR_CLASSES], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc427a",
   "metadata": {},
   "source": [
    "### Neural Network Architecture\n",
    "\n",
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd1b0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "# scientific notation for 0.0001:\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "# scientific notation for 0.001:\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# defining number of neuron per layer:\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe443c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function that will define layers of the neural network\n",
    "\n",
    "def setup_layer(input, weight_dim, bias_dim, name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
    "        w = tf.Variable(initial_value=initial_w, name='W')\n",
    "\n",
    "        initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
    "        b = tf.Variable(initial_value=initial_b, name='B')\n",
    "\n",
    "        layer_in = tf.matmul(input, w) + b\n",
    "        \n",
    "        if name=='out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "            \n",
    "        tf.summary.histogram('weights', w)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        \n",
    "        return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3e6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model with no dropout layer:\n",
    "\n",
    "# layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1],\n",
    "#                       bias_dim=[n_hidden1], name='layer_1')\n",
    "# \n",
    "# layer_2 = setup_layer(layer_1, weight_dim=[n_hidden1, n_hidden2],\n",
    "#                       bias_dim=[n_hidden2], name='layer_2')\n",
    "# \n",
    "# output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES],\n",
    "#                      bias_dim=[NR_CLASSES], name='out')\n",
    "# \n",
    "# model_name = f'{n_hidden1}-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12371f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1],\n",
    "                      bias_dim=[n_hidden1], name='layer_1')\n",
    "\n",
    "layer_drop = tf.nn.dropout(layer_1, keep_prob=0.8, name='dropout_layer')\n",
    "\n",
    "\n",
    "layer_2 = setup_layer(layer_drop, weight_dim=[n_hidden1, n_hidden2],\n",
    "                      bias_dim=[n_hidden2], name='layer_2')\n",
    "\n",
    "output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES],\n",
    "                     bias_dim=[NR_CLASSES], name='out')\n",
    "\n",
    "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b85af3",
   "metadata": {},
   "source": [
    "# Tensorboard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bbac72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created directories\n"
     ]
    }
   ],
   "source": [
    "# Folder for Tensorboard\n",
    "\n",
    "folder_name = f'{model_name} at {strftime(\"%H:%M\")}'\n",
    "\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "else:\n",
    "    print('Successfully created directories')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfaba44",
   "metadata": {},
   "source": [
    "# Loss, Optimization & Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa956f5d",
   "metadata": {},
   "source": [
    "#### Defining loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36946cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss from different data batches will require a mean calculus from each batch loss\n",
    "with tf.name_scope('loss_calc'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5f577",
   "metadata": {},
   "source": [
    "#### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22562644",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    # Minimizer\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b0768",
   "metadata": {},
   "source": [
    "#### Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a8bf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the predicted value against the actual value\n",
    "\n",
    "with tf.name_scope('accuracy_calc'):\n",
    "    correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ba52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('performance'):\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('cost', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb0c2b",
   "metadata": {},
   "source": [
    "#### Check Input Images in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3b051ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('show_image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    tf.summary.image('image_input', x_image, max_outputs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dabfa0",
   "metadata": {},
   "source": [
    "# Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba4a6d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 22:58:37.933056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935a2cc",
   "metadata": {},
   "source": [
    "#### Setup Filewriter and Merge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc909bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(directory + '/train')\n",
    "train_writer.add_graph(sess.graph)\n",
    "\n",
    "validation_writer = tf.summary.FileWriter(directory + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de5df45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 22:58:38.027364: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "# Initialise all the variables \n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d370aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising weights and biases for each layer in the neural network\n",
    "# w1.eval(sess)\n",
    "# b1.eval(sess)\n",
    "# b3.eval(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cf643",
   "metadata": {},
   "source": [
    "# Batching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed757d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2ea4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = y_train.shape[0]\n",
    "nr_iterations = int(num_examples/size_of_batch)\n",
    "\n",
    "index_in_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8d57517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data [start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b611e2",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57a8ea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 \t| Training Accuracy = 0.847000002861023\n",
      "Epoch1 \t| Training Accuracy = 0.8610000014305115\n",
      "Epoch2 \t| Training Accuracy = 0.8659999966621399\n",
      "Epoch3 \t| Training Accuracy = 0.8669999837875366\n",
      "Epoch4 \t| Training Accuracy = 0.8759999871253967\n",
      "Epoch5 \t| Training Accuracy = 0.8790000081062317\n",
      "Epoch6 \t| Training Accuracy = 0.9760000109672546\n",
      "Epoch7 \t| Training Accuracy = 0.9779999852180481\n",
      "Epoch8 \t| Training Accuracy = 0.9800000190734863\n",
      "Epoch9 \t| Training Accuracy = 0.9789999723434448\n",
      "Epoch10 \t| Training Accuracy = 0.9860000014305115\n",
      "Epoch11 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch12 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch13 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch14 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch15 \t| Training Accuracy = 0.9890000224113464\n",
      "Epoch16 \t| Training Accuracy = 0.9869999885559082\n",
      "Epoch17 \t| Training Accuracy = 0.9890000224113464\n",
      "Epoch18 \t| Training Accuracy = 0.9890000224113464\n",
      "Epoch19 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch20 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch21 \t| Training Accuracy = 0.9900000095367432\n",
      "Epoch22 \t| Training Accuracy = 0.9879999756813049\n",
      "Epoch23 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch24 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch25 \t| Training Accuracy = 0.9909999966621399\n",
      "Epoch26 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch27 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch28 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch29 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch30 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch31 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch32 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch33 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch34 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch35 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch36 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch37 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch38 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch39 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch40 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch41 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch42 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch43 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch44 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch45 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch46 \t| Training Accuracy = 0.9919999837875366\n",
      "Epoch47 \t| Training Accuracy = 0.9929999709129333\n",
      "Epoch48 \t| Training Accuracy = 0.9940000176429749\n",
      "Epoch49 \t| Training Accuracy = 0.9940000176429749\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    # =============== Training Dataset ================\n",
    "    \n",
    "    for i in range(nr_iterations):\n",
    "        # Defining batches for training\n",
    "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_train, labels=y_train)\n",
    "        # feed dictionary is necessary for sess to run\n",
    "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dictionary)\n",
    "        \n",
    "    # s stands for summary\n",
    "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict=feed_dictionary)\n",
    "    \n",
    "    train_writer.add_summary(s, epoch)\n",
    "    \n",
    "    print(f'Epoch{epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
    "    \n",
    "    # ============== Validation Dataset ================\n",
    "    \n",
    "    summary = sess.run(fetches=merged_summary, feed_dict={X:x_val, Y:y_val})\n",
    "    validation_writer.add_summary(summary, epoch)\n",
    "    \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce3d19",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90a4c4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('MNIST/test_img.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43964188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting image to gray scale with:\n",
    "bw = img.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3865f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverting image so it can be processed by our model:\n",
    "img_array = np.invert(bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22c1c163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39fb360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the img_array to just one dimension\n",
    "test_img = img_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32a5c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cffe7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding test_img to TensorFlow\n",
    "prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e745bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image is: [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction for test image is: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a593a",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7ffe4",
   "metadata": {},
   "source": [
    "**Challenge:** Calculate the accuracy over the test dataset(x_test, y_test). Use your Knowledgeof running session to get the accuracy. Display the accuracy as a percentage rounded to two decimal numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff8d2ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 97.75%\n"
     ]
    }
   ],
   "source": [
    "# accuracy can be fetched because it was defined before for our model\n",
    "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test, Y:y_test_all})\n",
    "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107de99c",
   "metadata": {},
   "source": [
    "# Reset for the Next Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41f74883",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76297898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e36d00",
   "metadata": {},
   "source": [
    "# Code for 1st part of module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c544719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST HIDDEN LAYER:\n",
    "\n",
    "# with tf.name_scope('initial_layer'):\n",
    "# \n",
    "#     # defining initial weight\n",
    "#     initial_w1 = tf.truncated_normal(shape=[TOTAL_INPUTS, n_hidden1], stddev=0.1, seed=42)\n",
    "#     # Creating a TensorFlow variable called 'weight one' that will hold all the weights in the first hidden layer\n",
    "#     w1 = tf.Variable(initial_value=initial_w1, name='w1')\n",
    "#     \n",
    "#     # Defining biases that will affect activation function for the neuron in the hidden layer\n",
    "#     initial_b1 = tf.constant(value=0.0, shape=[n_hidden1])\n",
    "#     b1 = tf.Variable(initial_value=initial_b1, name='b1')\n",
    "#     \n",
    "#     # tf.matmul is multiplying vectors from the first layer and its weights\n",
    "#     layer1_in = tf.matmul(X, w1) + b1\n",
    "#     \n",
    "#     # Output for the first hidden layer and its activation function\n",
    "#     layer1_out = tf.nn.relu(layer1_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744bd85",
   "metadata": {},
   "source": [
    "**Challenge:** Set up the second hidden layer. This layer has 64 neurons and needs to work the output of the first hidden layer. Then set up the output layer. The output layer will use the softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95abc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND HIDDEN LAYER:\n",
    "\n",
    "# with tf.name_scope('second_layer'):\n",
    "# \n",
    "#     # Weights for the second hidden layer - shape first arg gets the number of neurons from the hidden layer 1\n",
    "#     initial_w2 = tf.truncated_normal(shape=[n_hidden1, n_hidden2], stddev=0.1, seed=42)\n",
    "#     w2 = tf.Variable(initial_value=initial_w2, name='w2')\n",
    "# \n",
    "#     # Biases for the second hidden layer\n",
    "#     initial_b2 = tf.constant(value=0.0, shape=[n_hidden2])\n",
    "#     b2 = tf.Variable(initial_value=initial_b2, name='b2')\n",
    "# \n",
    "#     # input for second hidden layer:\n",
    "#     layer2_in = tf.matmul(layer1_out, w2) + b2\n",
    "#     layer2_out = tf.nn.relu(layer2_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47278e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FINAL - OUTPUT LAYER:\n",
    "\n",
    "# with tf.name_scope('output_layer'):\n",
    "# \n",
    "#     # Weights for the second hidden layer - shape is number of neurons from the hidden layer 2 and the cathegories\n",
    "#     initial_w3 = tf.truncated_normal(shape=[n_hidden2, NR_CLASSES], stddev=0.1, seed=42)\n",
    "#     w3 = tf.Variable(initial_value=initial_w3, name='w3')\n",
    "# \n",
    "#     # Biases for the second hidden layer - shape is the number of classes we want to predict\n",
    "#     initial_b3 = tf.constant(value=0.0, shape=[NR_CLASSES])\n",
    "#     b3 = tf.Variable(initial_value=initial_b3, name='b3')\n",
    "# \n",
    "#     # input for second hidden layer:\n",
    "#     layer3_in = tf.matmul(layer2_out, w3) + b3\n",
    "#     output = tf.nn.softmax(layer3_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
